############# MODELOS DE REGRESIÓN #########################################################################################
### modelos de regresión lineal
## un modelo es saturado si hay tantos parámetros como observaciones 
require(XLConnect)
install.packages("XLConnect")
setwd("C://Users//USUARIO//Documents")
x11(width = 7,height = 6,pointsize = 12)

curve(expr = x^2,xlim = c(-1,2),col="red",main="Gráfica de f(x)=x^2",xlab = "x",ylab = "f(x)", panel.first=grid(col="gray",lty = "dotted"))

### Gráfica para un modelo de regresión logística
par(mfrow=c(1,2))
beta0<-1
beta1<-0.5
curve(expr =exp(beta0+beta1*x)/(1+exp(beta0+beta1*x)),xlim = c(-15,15),col="black",main=expression(pi==frac( e^{1+0.5*x[1]},1+e^{1+0.5*x[1]})),xlab=expression(x[1]),ylab=expression(pi)) #expression ayuda a poner simbolos

curve(expr =exp(beta0-beta1*x)/(1+exp(beta0-beta1*x)),xlim = c(-15,15),col="black",main=expression(pi==frac( e^{1-0.5*x[1]},1+e^{1-0.5*x[1]})),xlab=expression(x[1]),ylab=expression(pi)) #expression ayuda a poner simbolos

placekick<-read.table(file="Placekick.csv",header = T,sep = ",")### este archivo está centrado en goles de campo 
tail(placekick)


### estimando un modelo de regresión para los datos
mod.fit<-glm(formula=good~ distance, family = binomial(link = logit),data = placekick)## glm es modelo lineal generalizado, lado izquierdo variable dependiente 
mod.fit
## cuando ponemos link=logit, simplemente establecemos que el logit(pi)=beta0+beta1x
##intercept=beta0,distance=beta1, cuando el coeficiente de beta1 es negativo
## la probabilidad de que un gol de campo sea exitoso va decreciendo conforme la distancia va aumentando (porque beta1=-0.115)

names(mod.fit)
class(mod.fit)
### funcion vcoc es la matriz de varianzas covarianzas
vcov(mod.fit)


######################### CUANDO HAY VARIAS VARIABLES INDEPENDIENTES#############
mod.fit2<-glm(formula=good~ distance+change , family = binomial(link = logit),data = placekick)## glm es modelo lineal generalizado, lado izquierdo variable dependiente 
mod.fit2## se usa logit porque es un modelo de regresión logistica 
#
#Coefficients:
#  (Intercept)     distance       change  
#       5.8932      -0.1129      -0.4478 
#LA PROBABILIDAD DE EXITOS DE UN GOL DE CAMPO DECRECE SI AUMENTA LA DISTANCIA O SI HAY UN CAMBIO EN EL LIDEREO DE PUNTUACIÓN
summary(mod.fit)




################ OBTENIENDO VARIANZAS Y COVARIANZAS DEL MODELO
temp<-summary(mod.fit)
names(temp)

temp$coefficients

############ MATRIZ DE COVARIANZAS
vcov(mod.fit)

#varianza de beta1
vcov(mod.fit)[2,2]

########## maximizar una fucnion equivale a maximizar el logaritmo de la función en cuestión
##función de , log-verosimilitud.### al maximizar la funcion de verosimilitud se obtienen los parámetros de la regresión 

logL<-function(beta,x,y) {
  pi<-exp(beta[1]+beta[2]*x)/(1+exp(beta[1]+beta[2]*x))
  sum(y*log(pi)+(1-y)*log(1-pi))
  
}

LogL(beta = mod.fit$coefficients,x=placekick$distance,y=placekick$good)
### da -387.8725, se tiene que comparar si en realidad se maximicó el logaritmo de la función,se hace con lo siguiente
logLik(mod.fit)### es el logaritmo de la función de verosimilitud 


## daremos valores iniciales para poder ajustar un modelo con la función opptim , o sea optimizar los parámetros
reg.mod<-lm(good~distance,placekick)#el acertar depende de la distancia?
reg.mod$coefficients## valores iniciale spara empezar a optimizar

mod.fit.optim<-optim(reg.mod$coefficients,logL,hessian = T,x = placekick$distance,Y= placekick$good,control = list(fnscale=-1),method = "BFGS")##optim por defecto minimiza la función y con el fnscale=-1 maximiza


mod.fit.optim$par


#Para hacer la gráfica 
beta0.values<-seq(from = -5,to=18,by=0.1)
beta1.values<-seq(from = -0.65,to=0.25,by=0.01)
### para facilitar la graficación también


count<-1
save.logL<-numeric(length(beta0.values)*length(beta1.values))
for(beta0 in beta0.values){
  for(beta1 in beta1.values){
    save.logL[count]<-logL(beta=c(beta0,beta1),x=placekick$distance,Y= placekick$good)
    count<-count+1
    
  }  
  
}
max(save.logL)  
library(rgl)
open3d()





# en el caso en que nuestros dstos no esten codificados con 0 1, vamos a demostrar que la foma de definir el modelo debe ser la misma solo midificando los datos

#redefiniendo los datos en forma binomial
##Proporción de éxitos para cada distancia
w<-aggregate(good~distance,placekick,sum)# esto solo dice cuandtos numeros de exitos se obtuvieron para cada distanciua
n<-aggregate(good~distance,placekick,length)
w.n<-data.frame(distance=w$distance,success=w$good,trials=n$good,proportion=round(w$good/n$good,4))
head(w.n)
##haremos la comparación con el primero que hicimos

mod.fit.bin<-glm(success/trials~distance,weights=trials,binomial(link=logit),w.n,trace=T)## cuando tenemos los datos en forma binomial debemos agregar el weights para que pondere bien 
summary(mod.fit.bin)





############################ PRUEBAS DE HIPOTESIS PARA LOS PARAMETROS DE REGRESIÓN###########################################
#Esto sirve para saber si una variable es realmente importante para el modelo o no
install.packages("car")
library(car)

### Ajustar un modelo que incluya la variable change y distance
mod.fit2<-glm(good~change+distance,binomial(link = logit),placekick)
round(summary(mod.fit2)$coefficients,4)#esto con el sumary da la prueba de WALD 
#De manera alterna podemos usar la paqueteria car, funcion anova nos permitirá obtener la prueba de WALD
Anova(mod.fit2,test.statistic = "Wald")


# Para la prueba de LRT
Anova(mod.fit2, test.statistic = "LR")
## OTRA FORMA DE HACER LA LRT ES USAR ANOVA CON MINUSCUALS
anova(mod.fit2,test = "Chisq")## para comparar dos modelos, dos ajustes 
## como pr(>chi) se rechaza la nula que es decir que se acepta la alternativa, o sea la cariable distancia es de importancia 
# con la columna de la variable distance se dice que como p value tambien es menor a 0.5 las dos variables son de importancia 
Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    
#NULL                      1424    1013.43              
#change    1   24.277      1423     989.15 8.343e-07 ***  Ho=b0 y H1=Bo+B1change
#  distance  1  218.650      1422     770.50 < 2.2e-16 ***Ho=b0+B1change y H1=Bo+B1change+b2Distance
#  ---
#  Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
#> 

summary(mod.fit2)
##### aqui se analiza ,b1 es change, z value es el estadictico de wald , el p value es el que dice si se acepta o rechaza la hipotesis nula, no siempre es 95% el valor de significancia 


Anova(mod.fit2, test.statistic = "LR")
## HIPOTESIS NULA BI=O ALTERNATIVA B1 DIFERENTE DE CERO
#LR CHISQ)-2log(lambda), aqui da 5.246 con valor p o.022 , se rechaza la hipotesis nula, por tanto b1 si importa en el modelo y no valdrá 0 



#si ahora queremos

#Ho=b0+B1distance y H1=Bo+B1change+b2Distance

mod.fit.Ho<-glm(good~distance,family = binomial(link = logit),placekick )
anova(mod.fit.Ho,mod.fit2,test = "Chisq")





## si queremos #Ho=b0 H1=Bo+B1change
mod.fit.Ho<-glm(good~1,family = binomial(link = logit),placekick )
mod.fit.Ha<-glm(good~change,family = binomial(link = logit),placekick )
anova(mod.fit.Ho,mod.fit.Ha,test = "Chisq")


pi.hat.Ho<-mod.fit.Ho$fitted.values
pi.hat.Ha<-mod.fit.Ha$fitted.values
y<-placekick$good
### para sacar el -2log
stat<--2*sum(y*log(pi.hat.Ho/pi.hat.Ha)+(1-y)*log((1-pi.hat.Ho)/(1-pi.hat.Ha)))##-2log(lambda)
pvalues<-1-pchisq(q=stat,df=1)
data.frame(stat,pvalues)


#B1 gorro se saca del glm y despues $fitted o $coefficients


###################### 




